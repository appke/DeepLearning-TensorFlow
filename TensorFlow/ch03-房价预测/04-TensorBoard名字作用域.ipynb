{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard 名字作用域梳理结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_feature(df):\n",
    "    return df.apply(lambda column: (column - column.mean()) / column.std())\n",
    "\n",
    "df = pd.read_csv('data1.csv', names=['square', 'bedrooms', 'price'])\n",
    "df = normalize_feature(df)\n",
    "\n",
    "ones = pd.DataFrame({'ones': np.ones(len(df))})\n",
    "df = pd.concat([ones, df], axis=1)\n",
    "\n",
    "X_data = np.array(df[['ones', 'square', 'bedrooms']])\n",
    "y_data = np.array(df[['price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 \t Loss=0.4116 \t Model: y = 3.353e-10 + 0.0791x1 + 0.03948x2\n",
      "Epoch 20 \t Loss=0.353 \t Model: y = -5.588e-11 + 0.1489x1 + 0.07135x2\n",
      "Epoch 30 \t Loss=0.3087 \t Model: y = 3.912e-10 + 0.2107x1 + 0.09676x2\n",
      "Epoch 40 \t Loss=0.2748 \t Model: y = -1.863e-11 + 0.2655x1 + 0.1167x2\n",
      "Epoch 50 \t Loss=0.2489 \t Model: y = 1.77e-10 + 0.3142x1 + 0.1321x2\n",
      "Epoch 60 \t Loss=0.2288 \t Model: y = -4.47e-10 + 0.3576x1 + 0.1436x2\n",
      "Epoch 70 \t Loss=0.2131 \t Model: y = -8.103e-10 + 0.3965x1 + 0.1519x2\n",
      "Epoch 80 \t Loss=0.2007 \t Model: y = -6.985e-10 + 0.4313x1 + 0.1574x2\n",
      "Epoch 90 \t Loss=0.1908 \t Model: y = -4.936e-10 + 0.4626x1 + 0.1607x2\n",
      "Epoch 100 \t Loss=0.1828 \t Model: y = -6.147e-10 + 0.4909x1 + 0.1621x2\n",
      "Epoch 110 \t Loss=0.1763 \t Model: y = -7.87e-10 + 0.5165x1 + 0.162x2\n",
      "Epoch 120 \t Loss=0.1709 \t Model: y = -5.821e-10 + 0.5397x1 + 0.1606x2\n",
      "Epoch 130 \t Loss=0.1664 \t Model: y = -9.08e-10 + 0.5609x1 + 0.1581x2\n",
      "Epoch 140 \t Loss=0.1625 \t Model: y = -9.965e-10 + 0.5802x1 + 0.1549x2\n",
      "Epoch 150 \t Loss=0.1592 \t Model: y = -9.756e-10 + 0.5979x1 + 0.1509x2\n",
      "Epoch 160 \t Loss=0.1564 \t Model: y = -4.144e-10 + 0.6142x1 + 0.1465x2\n",
      "Epoch 170 \t Loss=0.1539 \t Model: y = -1.001e-10 + 0.6292x1 + 0.1416x2\n",
      "Epoch 180 \t Loss=0.1518 \t Model: y = -3.236e-10 + 0.643x1 + 0.1364x2\n",
      "Epoch 190 \t Loss=0.1498 \t Model: y = -6.286e-11 + 0.6559x1 + 0.131x2\n",
      "Epoch 200 \t Loss=0.1481 \t Model: y = 2.119e-10 + 0.6678x1 + 0.1255x2\n",
      "Epoch 210 \t Loss=0.1466 \t Model: y = -1.956e-10 + 0.6789x1 + 0.1199x2\n",
      "Epoch 220 \t Loss=0.1452 \t Model: y = -1.758e-10 + 0.6892x1 + 0.1142x2\n",
      "Epoch 230 \t Loss=0.1439 \t Model: y = -4.307e-11 + 0.6989x1 + 0.1085x2\n",
      "Epoch 240 \t Loss=0.1428 \t Model: y = 3.376e-10 + 0.708x1 + 0.1029x2\n",
      "Epoch 250 \t Loss=0.1418 \t Model: y = 2.841e-10 + 0.7165x1 + 0.09736x2\n",
      "Epoch 260 \t Loss=0.1408 \t Model: y = 3.295e-10 + 0.7245x1 + 0.09189x2\n",
      "Epoch 270 \t Loss=0.14 \t Model: y = -8.033e-11 + 0.732x1 + 0.08653x2\n",
      "Epoch 280 \t Loss=0.1392 \t Model: y = 1.141e-10 + 0.7391x1 + 0.08128x2\n",
      "Epoch 290 \t Loss=0.1385 \t Model: y = 1.321e-10 + 0.7458x1 + 0.07616x2\n",
      "Epoch 300 \t Loss=0.1378 \t Model: y = 5.087e-10 + 0.7522x1 + 0.07118x2\n",
      "Epoch 310 \t Loss=0.1372 \t Model: y = 7.398e-10 + 0.7582x1 + 0.06634x2\n",
      "Epoch 320 \t Loss=0.1367 \t Model: y = 6.845e-10 + 0.7639x1 + 0.06165x2\n",
      "Epoch 330 \t Loss=0.1362 \t Model: y = 8.423e-10 + 0.7693x1 + 0.0571x2\n",
      "Epoch 340 \t Loss=0.1357 \t Model: y = 9.252e-10 + 0.7744x1 + 0.0527x2\n",
      "Epoch 350 \t Loss=0.1353 \t Model: y = 1.104e-09 + 0.7793x1 + 0.04845x2\n",
      "Epoch 360 \t Loss=0.1349 \t Model: y = 1.145e-09 + 0.784x1 + 0.04435x2\n",
      "Epoch 370 \t Loss=0.1346 \t Model: y = 1.631e-09 + 0.7884x1 + 0.0404x2\n",
      "Epoch 380 \t Loss=0.1343 \t Model: y = 1.446e-09 + 0.7926x1 + 0.03658x2\n",
      "Epoch 390 \t Loss=0.134 \t Model: y = 1.429e-09 + 0.7966x1 + 0.03291x2\n",
      "Epoch 400 \t Loss=0.1337 \t Model: y = 1.694e-09 + 0.8004x1 + 0.02938x2\n",
      "Epoch 410 \t Loss=0.1334 \t Model: y = 1.697e-09 + 0.8041x1 + 0.02598x2\n",
      "Epoch 420 \t Loss=0.1332 \t Model: y = 2.125e-09 + 0.8076x1 + 0.02271x2\n",
      "Epoch 430 \t Loss=0.133 \t Model: y = 2.292e-09 + 0.8109x1 + 0.01957x2\n",
      "Epoch 440 \t Loss=0.1328 \t Model: y = 2.913e-09 + 0.8141x1 + 0.01655x2\n",
      "Epoch 450 \t Loss=0.1326 \t Model: y = 3.412e-09 + 0.8171x1 + 0.01366x2\n",
      "Epoch 460 \t Loss=0.1325 \t Model: y = 3.749e-09 + 0.82x1 + 0.01087x2\n",
      "Epoch 470 \t Loss=0.1323 \t Model: y = 3.499e-09 + 0.8228x1 + 0.008204x2\n",
      "Epoch 480 \t Loss=0.1322 \t Model: y = 3.663e-09 + 0.8254x1 + 0.005641x2\n",
      "Epoch 490 \t Loss=0.1321 \t Model: y = 4.2e-09 + 0.828x1 + 0.003183x2\n",
      "Epoch 500 \t Loss=0.132 \t Model: y = 4.138e-09 + 0.8304x1 + 0.0008239x2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "alpha = 0.01 # 学习率\n",
    "epoch = 500  # 训练全量数据集的轮数\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, X_data.shape)\n",
    "    y = tf.placeholder(tf.float32, y_data.shape)\n",
    "\n",
    "with tf.name_scope('hypothesis'):\n",
    "    W = tf.get_variable(\"weights\", (X_data.shape[1], 1), initializer=tf.constant_initializer)\n",
    "    y_pred = tf.matmul(X, W)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss_op = 1 / (2*len(X_data)) * tf.matmul((y_pred - y), (y_pred - y), transpose_a=True)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    opt = tf.train.GradientDescentOptimizer(learning_rate=alpha)\n",
    "    train_op = opt.minimize(loss_op)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 初始化全局变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 创建 FileWrite实例\n",
    "    writer = tf.summary.FileWriter('./summary/linear-refression-1/', sess.graph)\n",
    "    # 开始训练模型，\n",
    "    # 因为训练集较小，所以每轮都使用全量数据训练\n",
    "    for e in range(1, epoch+1):\n",
    "        sess.run(train_op, feed_dict={X: X_data, y:y_data})\n",
    "        if e % 10 == 0:\n",
    "            loss, w = sess.run([loss_op, W], feed_dict={X: X_data, y:y_data})\n",
    "            log_str = \"Epoch %d \\t Loss=%.4g \\t Model: y = %.4g + %.4gx1 + %.4gx2\"\n",
    "            print(log_str % (e, loss, w[0], w[1], w[2]))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
